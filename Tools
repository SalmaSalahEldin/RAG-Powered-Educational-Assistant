import logging
from typing import List, Dict, Optional
from langchain_core.documents import Document
from pydantic import BaseModel, Field
from langchain_core.messages import AIMessage
from langchain.tools import StructuredTool
from langchain.vectorstores import Chroma
from langchain.prompts import PromptTemplate
import json
import os
from datetime import datetime
from dotenv import load_dotenv
from File_Service import AiCompanyFileService
from langchain.agents import Tool, initialize_agent, AgentType
from langchain.chat_models import ChatOpenAI

load_dotenv()

chatbot = AiCompanyFileService()

logging.basicConfig(level=logging.DEBUG, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

class GetTopicSchema(BaseModel):
    book_title: str = Field(..., description="The title of the book or document from which topics are being extracted")
    extraction_timestamp: str = Field(..., description="Timestamp of when the topics were extracted, in ISO format")
    main_topics: List[str] = Field(..., description="A list of the main topics extracted from the book/document")

class GetQuestionSchema(BaseModel):
    topic: str = Field(..., description="The topic to which the question belongs")
    question: str = Field(..., description="The actual question text")
    options: List[str] = Field(..., description="A list of 4 answer options (A, B, C, D)")
    correct_answer: str = Field(..., description="The correct answer option (A, B, C, or D)")
    explanation: str = Field(..., description="A detailed explanation of why the correct answer is correct")
    source: Dict[str, Optional[str]] = Field(...,
                                             description="Source data for the answer, including context and confidence score")

class EmptyArgsSchema(BaseModel):
    pass

def extract_topics_tool(vector_store: Chroma) -> StructuredTool:
    def tool_func(*args, **kwargs) -> GetTopicSchema:
        return extract_topics_from_chroma(vector_store)

    return StructuredTool(
        name="extract_topics",
        description="Extract main topics from the stored vector data.",
        func=tool_func,
        args_schema=EmptyArgsSchema
    )

def generate_questions_tool(vector_store: Chroma) -> StructuredTool:
    def tool_func(topic: str) -> List[Dict]:
        return generate_questions_for_topic(topic, vector_store)

    return StructuredTool(
        name="generate_questions",
        description="Generate multiple-choice questions based on book topics and vector store context.",
        func=tool_func,
        args_schema=EmptyArgsSchema
    )

def extract_topics_from_chroma(vector_store: Chroma) -> GetTopicSchema:
    logger.debug("Extracting topics from Chroma vector store...")

    if vector_store is None:
        raise ValueError("The Chroma vector store is not initialized.")

    documents = vector_store.similarity_search("", k=10)
    all_text = " ".join([doc.page_content for doc in documents])

    prompt_template = """
    Based on the following text, extract the main topics or themes discussed throughout the document.
    Provide a list of 5-10 topics that are most relevant and important across the content:

    Content:
    {content}
    """
    prompt = PromptTemplate(input_variables=["content"], template=prompt_template)

    model = ChatOpenAI(model="gpt-4o", temperature=0.0)
    try:
        response = model.invoke(prompt.format(content=all_text))
    except Exception as e:
        logger.error("Error invoking model: %s", e)
        raise

    if isinstance(response, AIMessage):
        response_text = response.content
    else:
        raise ValueError(f"Unexpected response type: {type(response)}. Expected 'AIMessage'.")

    main_topics = []
    for line in response_text.split("\n"):
        line = line.strip()
        if line and line[0].isdigit() and '.' in line:
            topic = line.split('.', 1)[1].strip()
            main_topics.append(topic)

    logger.debug("Extracted topics: %s", main_topics)

    return GetTopicSchema(
        book_title="Project Management Professional Guide",
        extraction_timestamp=datetime.utcnow().isoformat(),
        main_topics=main_topics
    )


def generate_questions_for_topic(topic: str, vector_store: Chroma) -> dict[str, list[dict] | dict[str, str | int]]:
    logger.debug("Generating questions for topic: %s", topic)

    context, context_with_scores = retrieve_full_context(topic, vector_store)

    if not context:
        raise ValueError(f"No context found for topic: {topic}")

    model = ChatOpenAI(temperature=0.2, model='gpt-4')
    response = model.predict(
        f"""
        Based on the following content related to '{topic}', generate a set of multiple-choice questions (MCQs). For each question, provide:
        - A question
        - Four answer options (A, B, C, D)
        - The correct answer with its corresponding letter
        - A detailed explanation of why the correct answer is correct

        Content:
        {context}

        Example format:
        "questions": [
            {{
                "id": "Q1",
                "topic": "Project Initiation",
                "type": "MCQ",
                "question": {{question}},
                "options": {{options}},
                "correct_answer": {{correct_answer}},
                "explanation": {{explanation}},
                "source": {{source}}
            }}
        ]

        """
    )

    logger.debug("Raw response from model: %s", response)

    questions = parse_questions_from_response(response, context_with_scores)

    metadata = {
        "generated_at": datetime.utcnow().isoformat(),
        "total_questions": len(questions),
        "book_title": "Project Management Professional Guide",
        "generation_method": "RAG Pipeline",
        "embedding_model": "text-embedding-3-large",
        "vector_store": "Chroma"
    }

    final_output = {
        "metadata": metadata,
        "questions": questions
    }

    results_folder = "Results"

    if not os.path.exists(results_folder):
        os.makedirs(results_folder)

    output_filename = f"generated_questions_{topic.replace(' ', '_')}_{datetime.utcnow().isoformat()}.json"

    output_path = os.path.join(results_folder, output_filename)

    with open(output_path, "w") as output_file:
        json.dump(final_output, output_file, indent=4)

    logger.info(f"Generated questions for topic '{topic}' have been saved to {output_filename}")

    return final_output


def retrieve_full_context(topic: str, vector_store: Chroma) -> tuple[str, list[tuple[Document, float]]]:
    logger.debug("Retrieving full context for topic: %s", topic)

    context_with_scores = vector_store.similarity_search_with_score(topic, k=10)

    context = " ".join([doc.page_content for doc, score in context_with_scores])

    return context, context_with_scores

def parse_questions_from_response(response: str, context_with_scores: list) -> List[Dict]:
    try:
        clean_response = response.strip()

        if clean_response.startswith('"questions":'):
            clean_response = f"{{ {clean_response} }}"

        response_data = json.loads(clean_response)
        questions = response_data.get('questions', [])
        formatted_questions = []

        for idx, question in enumerate(questions):
            formatted_question = {
                "id": f"Q{idx + 1}",
                "topic": question.get('topic', ''),
                "type": "MCQ",
                "question": question.get('question', ''),
                "options": question.get('options', {}),
                "correct_answer": question.get('correct_answer', ''),
                "explanation": question.get('explanation', ''),
                "source": get_source_from_context(context_with_scores)
            }
            formatted_questions.append(formatted_question)

        return formatted_questions

    except json.JSONDecodeError as e:
        logger.error("Error parsing response: Invalid JSON format.")
        logger.error("Response content: %s", response)
        raise ValueError(f"Error parsing the response from the model: {e}. The response is not in valid JSON format.")
    except Exception as e:
        logger.error("Unexpected error: %s", str(e))
        raise ValueError("An unexpected error occurred while parsing the response.")


def get_source_from_context(context_with_scores: list) -> Dict[str, str]:
    best_match = context_with_scores[0]
    source_data = {
        "context": best_match[0].page_content,
        "confidence_score": best_match[1]
    }
    return source_data

def create_agent(vector_store):
    logger.debug("Creating Langchain agent with vector store...")
    extract_topics = extract_topics_tool(vector_store)
    generate_questions = generate_questions_tool(vector_store)

    tools = [
        Tool(
            name=extract_topics.name,
            func=extract_topics.func,
            description=extract_topics.description
        ),
        Tool(
            name=generate_questions.name,
            func=generate_questions.func,
            description=generate_questions.description
        )
    ]

    agent = initialize_agent(
        tools,
        ChatOpenAI(model="gpt-4o", temperature=0.0),
        agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,  #
        verbose=True
    )
    return agent


if __name__ == "__main__":
    vector_store = chatbot.chunks_vectorstore

    agent = create_agent(vector_store)

    response = agent.run("""### Task Overview:
        You are tasked with building a question generation system for a book. The system should process the content of the provided book and generate multiple-choice questions (MCQs) based on the main topics extracted from the text. The task is divided into two levels:
        
        ---
        
        ### Level 1: Basic Topic Extraction and MCQ Generation
        
        1. **Extract Key Topics:**
           - Process the provided book (in PDF format) to extract at least 5-10 main topics.
           - The topics should cover the core themes of the book, which may vary depending on the subject matter (e.g., history, science, business, etc.).
           - Ensure that the extracted topics are clearly defined and represent the essential concepts of the book.
        
        2. **Generate Multiple-Choice Questions (MCQs):**
           - For each extracted topic, generate 5 multiple-choice questions.
           - Each question should include:
             - A relevant question based on the topic.
             - Four answer options labeled A, B, C, D.
             - The correct answer (with the corresponding letter).
             - The page number or location where the answer can be found in the book.
        
        3. **Output Format:**
           - Save the extracted topics in `topics.json`:
           ```json
        {
            "metadata": {
                "generated_at": "2024-11-25T10:30:00Z",
                "total_questions": 50,
                "book_title": "Project Management Professional Guide",
                "generation_method": "RAG Pipeline",
                "embedding_model": "text-embedding-ada-002",
                "vector_store": "Chroma"
            },
            "questions": [
                {
                    "id": "Q1",
                    "topic": "Project Initiation",
                    "type": "MCQ",
                    "question": "What is the primary purpose of a project charter?",
                    "options": [
                        "A) Define project budget",
                        "B) Formally authorize the project",
                        "C) Assign project team",
                        "D) Schedule meetings"
                    ],
                    "correct_answer": "B",
                    "explanation": "A project charter formally authorizes the project and provides the project manager with the authority to apply organizational resources. This is clearly stated in Chapter 1, page 13, which discusses project initiation documents.",
                    "source": {
                        "page_number": 13,
                        "context": "The project charter serves as the formal authorization...",
                        "confidence_score": 0.92
                    }
                }
            ]
        } ```
        """)

    logger.info(f"Agent response: {response}")
